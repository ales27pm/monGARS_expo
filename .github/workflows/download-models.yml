name: Download ML Models

on:
  workflow_call:
    inputs:
      model_name:
        description: "Model to download"
        required: true
        type: string
    outputs:
      models_committed:
        description: "Whether models were committed"
        value: ${{ jobs.download.outputs.models_committed }}

env:
  MODELS_DIR: ./assets/models

jobs:
  download:
    name: Download Models
    runs-on: ubuntu-latest
    permissions:
      contents: write

    outputs:
      models_committed: ${{ steps.commit.outputs.committed }}

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          lfs: true

      - name: ğŸ—‚ï¸ Setup Git LFS
        run: |
          git lfs install
          git lfs track "*.gguf"
          git add .gitattributes
          echo "âœ… Git LFS configured for .gguf files"

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: ğŸ“¦ Install Python dependencies
        run: pip install huggingface-hub requests tqdm

      - name: ğŸ“ Create models directory
        run: mkdir -p ${{ env.MODELS_DIR }}

      - name: â¬‡ï¸ Download Qwen2 0.5B
        if: ${{ inputs.model_name == 'qwen2-0.5b' || inputs.model_name == 'all' }}
        run: |
          python - <<'EOF'
          from huggingface_hub import hf_hub_download
          import os
          print("ğŸ“¥ Downloading Qwen2 0.5B Instruct Q4_K_M...")
          file_path = hf_hub_download(
              repo_id="Qwen/Qwen2-0.5B-Instruct-GGUF",
              filename="qwen2-0_5b-instruct-q4_k_m.gguf",
              local_dir="${{ env.MODELS_DIR }}",
              local_dir_use_symlinks=False
          )
          print(f"âœ… Downloaded: {os.path.getsize(file_path) / (1024*1024):.2f} MB")
          EOF

      - name: â¬‡ï¸ Download Llama 3.2 1B
        if: ${{ inputs.model_name == 'llama-3.2-1b' || inputs.model_name == 'all' }}
        run: |
          python - <<'EOF'
          from huggingface_hub import hf_hub_download
          import os
          print("ğŸ“¥ Downloading Llama 3.2 1B Instruct Q4_K_M...")
          file_path = hf_hub_download(
              repo_id="ggml-org/Llama-3.2-1B-Instruct-GGUF",
              filename="Llama-3.2-1B-Instruct-Q4_K_M.gguf",
              local_dir="${{ env.MODELS_DIR }}",
              local_dir_use_symlinks=False
          )
          print(f"âœ… Downloaded: {os.path.getsize(file_path) / (1024*1024):.2f} MB")
          EOF

      - name: â¬‡ï¸ Download SmolLM2 1.7B
        if: ${{ inputs.model_name == 'smollm2-1.7b' || inputs.model_name == 'all' }}
        run: |
          python - <<'EOF'
          from huggingface_hub import hf_hub_download
          import os
          print("ğŸ“¥ Downloading SmolLM2 1.7B Instruct Q4_K_M...")
          file_path = hf_hub_download(
              repo_id="HuggingFaceTB/SmolLM2-1.7B-Instruct-GGUF",
              filename="smollm2-1.7b-instruct-q4_k_m.gguf",
              local_dir="${{ env.MODELS_DIR }}",
              local_dir_use_symlinks=False
          )
          print(f"âœ… Downloaded: {os.path.getsize(file_path) / (1024*1024):.2f} MB")
          EOF

      - name: â¬‡ï¸ Download Phi-3 Mini
        if: ${{ inputs.model_name == 'phi-3-mini' || inputs.model_name == 'all' }}
        run: |
          python - <<'EOF'
          from huggingface_hub import hf_hub_download
          import os
          print("ğŸ“¥ Downloading Phi-3 Mini 4K Instruct Q4...")
          file_path = hf_hub_download(
              repo_id="microsoft/Phi-3-mini-4k-instruct-gguf",
              filename="Phi-3-mini-4k-instruct-q4.gguf",
              local_dir="${{ env.MODELS_DIR }}",
              local_dir_use_symlinks=False
          )
          print(f"âœ… Downloaded: {os.path.getsize(file_path) / (1024*1024):.2f} MB")
          EOF

      - name: ğŸ“Š Verify models
        run: |
          echo "ğŸ“ Downloaded models:"
          ls -lh ${{ env.MODELS_DIR }}
          echo "ğŸ’¾ Total size:"
          du -sh ${{ env.MODELS_DIR }}

      - name: ğŸ’¾ Commit models with LFS
        id: commit
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Add models to LFS tracking
          git lfs track "*.gguf"
          git add .gitattributes

          # Add model files
          git add ${{ env.MODELS_DIR }}
          git add -A

          if git diff --staged --quiet; then
            echo "â„¹ï¸ No changes to commit"
            echo "committed=false" >> $GITHUB_OUTPUT
          else
            git commit -m "Add ML models: ${{ inputs.model_name }} [LFS]"

            # Push with LFS
            git lfs push --all origin main
            git push

            echo "âœ… Models committed and pushed with LFS"
            echo "committed=true" >> $GITHUB_OUTPUT
          fi
