name: Download ML Models and Build iOS App

on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Model to download (llama-3.2-1b, qwen2-0.5b, smollm2-1.7b, phi-3-mini, all)'
        required: true
        default: 'llama-3.2-1b'
        type: choice
        options:
          - llama-3.2-1b
          - qwen2-0.5b
          - smollm2-1.7b
          - phi-3-mini
          - all
      build_ios:
        description: 'Build iOS app with EAS Build after model download'
        required: false
        type: boolean
        default: true
      profile:
        description: 'EAS Build profile (development, preview, production)'
        required: false
        default: 'production'
        type: choice
        options:
          - development
          - preview
          - production

env:
  MODELS_DIR: ./models

jobs:
  download-models:
    name: Download ML Models
    runs-on: ubuntu-latest

    outputs:
      models_artifact: ${{ steps.upload.outputs.artifact-id }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install huggingface-hub requests tqdm

      - name: Create models directory
        run: |
          mkdir -p ${{ env.MODELS_DIR }}

      - name: Download Llama 3.2 1B Instruct
        if: ${{ inputs.model_name == 'llama-3.2-1b' || inputs.model_name == 'all' }}
        run: |
          python - <<EOF
          from huggingface_hub import hf_hub_download
          import os

          print("Downloading Llama 3.2 1B Instruct Q4_K_M...")
          file_path = hf_hub_download(
              repo_id="ggml-org/Llama-3.2-1B-Instruct-GGUF",
              filename="Llama-3.2-1B-Instruct-Q4_K_M.gguf",
              local_dir="${{ env.MODELS_DIR }}",
              local_dir_use_symlinks=False
          )
          print(f"Downloaded to: {file_path}")
          print(f"Size: {os.path.getsize(file_path) / (1024*1024):.2f} MB")
          EOF

      - name: Download Qwen2 0.5B Instruct
        if: ${{ inputs.model_name == 'qwen2-0.5b' || inputs.model_name == 'all' }}
        run: |
          python - <<EOF
          from huggingface_hub import hf_hub_download
          import os

          print("Downloading Qwen2 0.5B Instruct Q4_K_M...")
          file_path = hf_hub_download(
              repo_id="Qwen/Qwen2-0.5B-Instruct-GGUF",
              filename="qwen2-0_5b-instruct-q4_k_m.gguf",
              local_dir="${{ env.MODELS_DIR }}",
              local_dir_use_symlinks=False
          )
          print(f"Downloaded to: {file_path}")
          print(f"Size: {os.path.getsize(file_path) / (1024*1024):.2f} MB")
          EOF

      - name: Download SmolLM2 1.7B Instruct
        if: ${{ inputs.model_name == 'smollm2-1.7b' || inputs.model_name == 'all' }}
        run: |
          python - <<EOF
          from huggingface_hub import hf_hub_download
          import os

          print("Downloading SmolLM2 1.7B Instruct Q4_K_M...")
          file_path = hf_hub_download(
              repo_id="HuggingFaceTB/SmolLM2-1.7B-Instruct-GGUF",
              filename="smollm2-1.7b-instruct-q4_k_m.gguf",
              local_dir="${{ env.MODELS_DIR }}",
              local_dir_use_symlinks=False
          )
          print(f"Downloaded to: {file_path}")
          print(f"Size: {os.path.getsize(file_path) / (1024*1024):.2f} MB")
          EOF

      - name: Download Phi-3 Mini 3.8B
        if: ${{ inputs.model_name == 'phi-3-mini' || inputs.model_name == 'all' }}
        run: |
          python - <<EOF
          from huggingface_hub import hf_hub_download
          import os

          print("Downloading Phi-3 Mini 4K Instruct Q4...")
          file_path = hf_hub_download(
              repo_id="microsoft/Phi-3-mini-4k-instruct-gguf",
              filename="Phi-3-mini-4k-instruct-q4.gguf",
              local_dir="${{ env.MODELS_DIR }}",
              local_dir_use_symlinks=False
          )
          print(f"Downloaded to: {file_path}")
          print(f"Size: {os.path.getsize(file_path) / (1024*1024):.2f} MB")
          EOF

      - name: List downloaded models
        run: |
          echo "Downloaded models:"
          ls -lh ${{ env.MODELS_DIR }}
          du -sh ${{ env.MODELS_DIR }}

      - name: Upload models as artifact
        id: upload
        uses: actions/upload-artifact@v4
        with:
          name: ml-models-${{ github.run_id }}
          path: ${{ env.MODELS_DIR }}
          retention-days: 7
          compression-level: 9

  build-ios:
    name: Build iOS App with EAS
    runs-on: ubuntu-latest
    needs: download-models
    if: ${{ inputs.build_ios }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      - name: Setup EAS
        uses: expo/expo-github-action@v8
        with:
          eas-version: latest
          token: ${{ secrets.EXPO_TOKEN }}

      - name: Download models artifact
        uses: actions/download-artifact@v4
        with:
          name: ml-models-${{ github.run_id }}
          path: ./assets/models

      - name: Verify models
        run: |
          echo "Models in assets:"
          ls -lh ./assets/models/
          du -sh ./assets/models/

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Create eas.json if not exists
        run: |
          if [ ! -f eas.json ]; then
            cat > eas.json <<'EASJSON'
          {
            "cli": {
              "version": ">= 5.0.0"
            },
            "build": {
              "development": {
                "developmentClient": true,
                "distribution": "internal",
                "ios": {
                  "resourceClass": "m-medium"
                }
              },
              "preview": {
                "distribution": "internal",
                "ios": {
                  "resourceClass": "m-medium"
                }
              },
              "production": {
                "ios": {
                  "resourceClass": "m-medium"
                }
              }
            },
            "submit": {
              "production": {
                "ios": {
                  "appleId": "$APPLE_ID",
                  "ascAppId": "$ASC_APP_ID",
                  "appleTeamId": "$APPLE_TEAM_ID"
                }
              }
            }
          }
          EASJSON
          fi

      - name: Build iOS with EAS
        run: |
          eas build --platform ios --profile ${{ inputs.profile }} --non-interactive --no-wait
        env:
          EXPO_TOKEN: ${{ secrets.EXPO_TOKEN }}

      - name: Get build URL
        run: |
          echo "Build started! Check status at:"
          echo "https://expo.dev/accounts/$(eas whoami)/projects/$(basename $(pwd))/builds"

  submit-to-app-store:
    name: Submit to App Store
    runs-on: ubuntu-latest
    needs: build-ios
    if: ${{ inputs.profile == 'production' && inputs.build_ios }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup EAS
        uses: expo/expo-github-action@v8
        with:
          eas-version: latest
          token: ${{ secrets.EXPO_TOKEN }}

      - name: Wait for build completion
        run: |
          echo "Waiting for EAS build to complete..."
          # This is a placeholder - in production, you'd poll EAS CLI
          sleep 300

      - name: Submit to App Store
        run: |
          eas submit --platform ios --profile production --latest --non-interactive
        env:
          EXPO_TOKEN: ${{ secrets.EXPO_TOKEN }}
          APPLE_ID: ${{ secrets.APPLE_ID }}
          APPLE_APP_SPECIFIC_PASSWORD: ${{ secrets.APPLE_APP_SPECIFIC_PASSWORD }}
