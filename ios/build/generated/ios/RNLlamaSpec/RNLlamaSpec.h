/**
 * This code was generated by [react-native-codegen](https://www.npmjs.com/package/react-native-codegen).
 *
 * Do not edit this file as changes may cause incorrect behavior and will be lost
 * once the code is regenerated.
 *
 * @generated by codegen project: GenerateModuleObjCpp
 *
 * We create an umbrella header (and corresponding implementation) here since
 * Cxx compilation in BUCK has a limitation: source-code producing genrule()s
 * must have a single output. More files => more genrule()s => slower builds.
 */

#ifndef __cplusplus
#error This file must be compiled as Obj-C++. If you are importing it, you must change your file extension to .mm.
#endif

// Avoid multiple includes of RNLlamaSpec symbols
#ifndef RNLlamaSpec_H
#define RNLlamaSpec_H

#import <Foundation/Foundation.h>
#import <RCTRequired/RCTRequired.h>
#import <RCTTypeSafety/RCTConvertHelpers.h>
#import <RCTTypeSafety/RCTTypedModuleConstants.h>
#import <React/RCTBridgeModule.h>
#import <React/RCTCxxConvert.h>
#import <React/RCTManagedPointer.h>
#import <ReactCommon/RCTTurboModule.h>
#import <optional>
#import <vector>


NS_ASSUME_NONNULL_BEGIN
namespace JS {
  namespace NativeRNLlama {
    struct NativeContextParamsLora_listElement {
      NSString *path() const;
      std::optional<double> scaled() const;

      NativeContextParamsLora_listElement(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeContextParamsLora_listElement)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeContextParamsLora_listElement:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeContextParams {
      NSString *model() const;
      NSString *chat_template() const;
      std::optional<bool> is_model_asset() const;
      std::optional<bool> use_progress_callback() const;
      std::optional<double> n_ctx() const;
      std::optional<double> n_batch() const;
      std::optional<double> n_ubatch() const;
      std::optional<double> n_parallel() const;
      std::optional<double> n_threads() const;
      std::optional<double> n_gpu_layers() const;
      std::optional<bool> no_gpu_devices() const;
      NSString *flash_attn_type() const;
      std::optional<bool> flash_attn() const;
      NSString *cache_type_k() const;
      NSString *cache_type_v() const;
      std::optional<bool> use_mlock() const;
      std::optional<bool> use_mmap() const;
      std::optional<bool> vocab_only() const;
      NSString *lora() const;
      std::optional<double> lora_scaled() const;
      std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeContextParamsLora_listElement>> lora_list() const;
      std::optional<double> rope_freq_base() const;
      std::optional<double> rope_freq_scale() const;
      std::optional<double> pooling_type() const;
      std::optional<bool> ctx_shift() const;
      std::optional<bool> kv_unified() const;
      std::optional<bool> swa_full() const;
      std::optional<double> n_cpu_moe() const;
      std::optional<bool> embedding() const;
      std::optional<double> embd_normalize() const;

      NativeContextParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeContextParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeContextParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct SpecGetFormattedChatParams {
      std::optional<bool> jinja() const;
      NSString *json_schema() const;
      NSString *tools() const;
      NSString *parallel_tool_calls() const;
      NSString *tool_choice() const;
      std::optional<bool> enable_thinking() const;
      std::optional<bool> add_generation_prompt() const;
      NSString *now() const;
      NSString *chat_template_kwargs() const;

      SpecGetFormattedChatParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_SpecGetFormattedChatParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_SpecGetFormattedChatParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeCompletionParamsGrammar_triggersElement {
      double type() const;
      NSString *value() const;
      double token() const;

      NativeCompletionParamsGrammar_triggersElement(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeCompletionParamsGrammar_triggersElement)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeCompletionParamsGrammar_triggersElement:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeCompletionParams {
      NSString *prompt() const;
      std::optional<double> n_threads() const;
      std::optional<bool> jinja() const;
      NSString *json_schema() const;
      NSString *grammar() const;
      std::optional<bool> grammar_lazy() const;
      std::optional<bool> enable_thinking() const;
      std::optional<bool> thinking_forced_open() const;
      std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement>> grammar_triggers() const;
      std::optional<facebook::react::LazyVector<NSString *>> preserved_tokens() const;
      std::optional<double> chat_format() const;
      NSString *reasoning_format() const;
      std::optional<facebook::react::LazyVector<NSString *>> media_paths() const;
      std::optional<facebook::react::LazyVector<NSString *>> stop() const;
      std::optional<double> n_predict() const;
      std::optional<double> n_probs() const;
      std::optional<double> top_k() const;
      std::optional<double> top_p() const;
      std::optional<double> min_p() const;
      std::optional<double> xtc_probability() const;
      std::optional<double> xtc_threshold() const;
      std::optional<double> typical_p() const;
      std::optional<double> temperature() const;
      std::optional<double> penalty_last_n() const;
      std::optional<double> penalty_repeat() const;
      std::optional<double> penalty_freq() const;
      std::optional<double> penalty_present() const;
      std::optional<double> mirostat() const;
      std::optional<double> mirostat_tau() const;
      std::optional<double> mirostat_eta() const;
      std::optional<double> dry_multiplier() const;
      std::optional<double> dry_base() const;
      std::optional<double> dry_allowed_length() const;
      std::optional<double> dry_penalty_last_n() const;
      std::optional<facebook::react::LazyVector<NSString *>> dry_sequence_breakers() const;
      std::optional<double> top_n_sigma() const;
      std::optional<bool> ignore_eos() const;
      std::optional<facebook::react::LazyVector<facebook::react::LazyVector<double>>> logit_bias() const;
      std::optional<double> seed() const;
      std::optional<facebook::react::LazyVector<double>> guide_tokens() const;
      bool emit_partial_completion() const;

      NativeCompletionParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeCompletionParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeCompletionParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct SpecEnableParallelModeParams {
      bool enabled() const;
      std::optional<double> n_parallel() const;
      std::optional<double> n_batch() const;

      SpecEnableParallelModeParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_SpecEnableParallelModeParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_SpecEnableParallelModeParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeParallelCompletionParamsGrammar_triggersElement {
      double type() const;
      NSString *value() const;
      double token() const;

      NativeParallelCompletionParamsGrammar_triggersElement(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeParallelCompletionParamsGrammar_triggersElement)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeParallelCompletionParamsGrammar_triggersElement:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeParallelCompletionParams {
      NSString *prompt() const;
      std::optional<double> n_threads() const;
      std::optional<bool> jinja() const;
      NSString *json_schema() const;
      NSString *grammar() const;
      std::optional<bool> grammar_lazy() const;
      std::optional<bool> enable_thinking() const;
      std::optional<bool> thinking_forced_open() const;
      std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeParallelCompletionParamsGrammar_triggersElement>> grammar_triggers() const;
      std::optional<facebook::react::LazyVector<NSString *>> preserved_tokens() const;
      std::optional<double> chat_format() const;
      NSString *reasoning_format() const;
      std::optional<facebook::react::LazyVector<NSString *>> media_paths() const;
      std::optional<facebook::react::LazyVector<NSString *>> stop() const;
      std::optional<double> n_predict() const;
      std::optional<double> n_probs() const;
      std::optional<double> top_k() const;
      std::optional<double> top_p() const;
      std::optional<double> min_p() const;
      std::optional<double> xtc_probability() const;
      std::optional<double> xtc_threshold() const;
      std::optional<double> typical_p() const;
      std::optional<double> temperature() const;
      std::optional<double> penalty_last_n() const;
      std::optional<double> penalty_repeat() const;
      std::optional<double> penalty_freq() const;
      std::optional<double> penalty_present() const;
      std::optional<double> mirostat() const;
      std::optional<double> mirostat_tau() const;
      std::optional<double> mirostat_eta() const;
      std::optional<double> dry_multiplier() const;
      std::optional<double> dry_base() const;
      std::optional<double> dry_allowed_length() const;
      std::optional<double> dry_penalty_last_n() const;
      std::optional<facebook::react::LazyVector<NSString *>> dry_sequence_breakers() const;
      std::optional<double> top_n_sigma() const;
      std::optional<bool> ignore_eos() const;
      std::optional<facebook::react::LazyVector<facebook::react::LazyVector<double>>> logit_bias() const;
      std::optional<double> seed() const;
      std::optional<facebook::react::LazyVector<double>> guide_tokens() const;
      bool emit_partial_completion() const;
      NSString *load_state_path() const;
      NSString *save_state_path() const;
      std::optional<double> save_state_size() const;

      NativeParallelCompletionParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeParallelCompletionParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeParallelCompletionParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeEmbeddingParams {
      std::optional<double> embd_normalize() const;

      NativeEmbeddingParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeEmbeddingParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeEmbeddingParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct NativeRerankParams {
      std::optional<double> normalize() const;

      NativeRerankParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_NativeRerankParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_NativeRerankParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct SpecInitMultimodalParams {
      NSString *path() const;
      bool use_gpu() const;

      SpecInitMultimodalParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_SpecInitMultimodalParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_SpecInitMultimodalParams:(id)json;
@end
namespace JS {
  namespace NativeRNLlama {
    struct SpecInitVocoderParams {
      NSString *path() const;
      std::optional<double> n_batch() const;

      SpecInitVocoderParams(NSDictionary *const v) : _v(v) {}
    private:
      NSDictionary *_v;
    };
  }
}

@interface RCTCxxConvert (NativeRNLlama_SpecInitVocoderParams)
+ (RCTManagedPointer *)JS_NativeRNLlama_SpecInitVocoderParams:(id)json;
@end
@protocol NativeRNLlamaSpec <RCTBridgeModule, RCTTurboModule>

- (void)toggleNativeLog:(BOOL)enabled
                resolve:(RCTPromiseResolveBlock)resolve
                 reject:(RCTPromiseRejectBlock)reject;
- (void)setContextLimit:(double)limit
                resolve:(RCTPromiseResolveBlock)resolve
                 reject:(RCTPromiseRejectBlock)reject;
- (void)modelInfo:(NSString *)path
             skip:(NSArray *)skip
          resolve:(RCTPromiseResolveBlock)resolve
           reject:(RCTPromiseRejectBlock)reject;
- (void)getBackendDevicesInfo:(RCTPromiseResolveBlock)resolve
                       reject:(RCTPromiseRejectBlock)reject;
- (void)initContext:(double)contextId
             params:(JS::NativeRNLlama::NativeContextParams &)params
            resolve:(RCTPromiseResolveBlock)resolve
             reject:(RCTPromiseRejectBlock)reject;
- (void)getFormattedChat:(double)contextId
                messages:(NSString *)messages
            chatTemplate:(NSString *)chatTemplate
                  params:(JS::NativeRNLlama::SpecGetFormattedChatParams &)params
                 resolve:(RCTPromiseResolveBlock)resolve
                  reject:(RCTPromiseRejectBlock)reject;
- (void)loadSession:(double)contextId
           filepath:(NSString *)filepath
            resolve:(RCTPromiseResolveBlock)resolve
             reject:(RCTPromiseRejectBlock)reject;
- (void)saveSession:(double)contextId
           filepath:(NSString *)filepath
               size:(double)size
            resolve:(RCTPromiseResolveBlock)resolve
             reject:(RCTPromiseRejectBlock)reject;
- (void)completion:(double)contextId
            params:(JS::NativeRNLlama::NativeCompletionParams &)params
           resolve:(RCTPromiseResolveBlock)resolve
            reject:(RCTPromiseRejectBlock)reject;
- (void)stopCompletion:(double)contextId
               resolve:(RCTPromiseResolveBlock)resolve
                reject:(RCTPromiseRejectBlock)reject;
- (void)enableParallelMode:(double)contextId
                    params:(JS::NativeRNLlama::SpecEnableParallelModeParams &)params
                   resolve:(RCTPromiseResolveBlock)resolve
                    reject:(RCTPromiseRejectBlock)reject;
- (void)queueCompletion:(double)contextId
                 params:(JS::NativeRNLlama::NativeParallelCompletionParams &)params
                resolve:(RCTPromiseResolveBlock)resolve
                 reject:(RCTPromiseRejectBlock)reject;
- (void)queueEmbedding:(double)contextId
                  text:(NSString *)text
                params:(JS::NativeRNLlama::NativeEmbeddingParams &)params
               resolve:(RCTPromiseResolveBlock)resolve
                reject:(RCTPromiseRejectBlock)reject;
- (void)queueRerank:(double)contextId
              query:(NSString *)query
          documents:(NSArray *)documents
             params:(JS::NativeRNLlama::NativeRerankParams &)params
            resolve:(RCTPromiseResolveBlock)resolve
             reject:(RCTPromiseRejectBlock)reject;
- (void)cancelRequest:(double)contextId
            requestId:(double)requestId
              resolve:(RCTPromiseResolveBlock)resolve
               reject:(RCTPromiseRejectBlock)reject;
- (void)tokenize:(double)contextId
            text:(NSString *)text
      mediaPaths:(NSArray *)mediaPaths
         resolve:(RCTPromiseResolveBlock)resolve
          reject:(RCTPromiseRejectBlock)reject;
- (void)detokenize:(double)contextId
            tokens:(NSArray *)tokens
           resolve:(RCTPromiseResolveBlock)resolve
            reject:(RCTPromiseRejectBlock)reject;
- (void)embedding:(double)contextId
             text:(NSString *)text
           params:(JS::NativeRNLlama::NativeEmbeddingParams &)params
          resolve:(RCTPromiseResolveBlock)resolve
           reject:(RCTPromiseRejectBlock)reject;
- (void)rerank:(double)contextId
         query:(NSString *)query
     documents:(NSArray *)documents
        params:(JS::NativeRNLlama::NativeRerankParams &)params
       resolve:(RCTPromiseResolveBlock)resolve
        reject:(RCTPromiseRejectBlock)reject;
- (void)bench:(double)contextId
           pp:(double)pp
           tg:(double)tg
           pl:(double)pl
           nr:(double)nr
      resolve:(RCTPromiseResolveBlock)resolve
       reject:(RCTPromiseRejectBlock)reject;
- (void)applyLoraAdapters:(double)contextId
             loraAdapters:(NSArray *)loraAdapters
                  resolve:(RCTPromiseResolveBlock)resolve
                   reject:(RCTPromiseRejectBlock)reject;
- (void)removeLoraAdapters:(double)contextId
                   resolve:(RCTPromiseResolveBlock)resolve
                    reject:(RCTPromiseRejectBlock)reject;
- (void)getLoadedLoraAdapters:(double)contextId
                      resolve:(RCTPromiseResolveBlock)resolve
                       reject:(RCTPromiseRejectBlock)reject;
- (void)initMultimodal:(double)contextId
                params:(JS::NativeRNLlama::SpecInitMultimodalParams &)params
               resolve:(RCTPromiseResolveBlock)resolve
                reject:(RCTPromiseRejectBlock)reject;
- (void)isMultimodalEnabled:(double)contextId
                    resolve:(RCTPromiseResolveBlock)resolve
                     reject:(RCTPromiseRejectBlock)reject;
- (void)getMultimodalSupport:(double)contextId
                     resolve:(RCTPromiseResolveBlock)resolve
                      reject:(RCTPromiseRejectBlock)reject;
- (void)releaseMultimodal:(double)contextId
                  resolve:(RCTPromiseResolveBlock)resolve
                   reject:(RCTPromiseRejectBlock)reject;
- (void)initVocoder:(double)contextId
             params:(JS::NativeRNLlama::SpecInitVocoderParams &)params
            resolve:(RCTPromiseResolveBlock)resolve
             reject:(RCTPromiseRejectBlock)reject;
- (void)isVocoderEnabled:(double)contextId
                 resolve:(RCTPromiseResolveBlock)resolve
                  reject:(RCTPromiseRejectBlock)reject;
- (void)getFormattedAudioCompletion:(double)contextId
                     speakerJsonStr:(NSString *)speakerJsonStr
                        textToSpeak:(NSString *)textToSpeak
                            resolve:(RCTPromiseResolveBlock)resolve
                             reject:(RCTPromiseRejectBlock)reject;
- (void)getAudioCompletionGuideTokens:(double)contextId
                          textToSpeak:(NSString *)textToSpeak
                              resolve:(RCTPromiseResolveBlock)resolve
                               reject:(RCTPromiseRejectBlock)reject;
- (void)decodeAudioTokens:(double)contextId
                   tokens:(NSArray *)tokens
                  resolve:(RCTPromiseResolveBlock)resolve
                   reject:(RCTPromiseRejectBlock)reject;
- (void)releaseVocoder:(double)contextId
               resolve:(RCTPromiseResolveBlock)resolve
                reject:(RCTPromiseRejectBlock)reject;
- (void)releaseContext:(double)contextId
               resolve:(RCTPromiseResolveBlock)resolve
                reject:(RCTPromiseRejectBlock)reject;
- (void)releaseAllContexts:(RCTPromiseResolveBlock)resolve
                    reject:(RCTPromiseRejectBlock)reject;

@end

@interface NativeRNLlamaSpecBase : NSObject {
@protected
facebook::react::EventEmitterCallback _eventEmitterCallback;
}
- (void)setEventEmitterCallback:(EventEmitterCallbackWrapper *)eventEmitterCallbackWrapper;


@end

namespace facebook::react {
  /**
   * ObjC++ class for module 'NativeRNLlama'
   */
  class JSI_EXPORT NativeRNLlamaSpecJSI : public ObjCTurboModule {
  public:
    NativeRNLlamaSpecJSI(const ObjCTurboModule::InitParams &params);
  };
} // namespace facebook::react
inline NSString *JS::NativeRNLlama::NativeContextParamsLora_listElement::path() const
{
  id const p = _v[@"path"];
  return RCTBridgingToString(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParamsLora_listElement::scaled() const
{
  id const p = _v[@"scaled"];
  return RCTBridgingToOptionalDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::model() const
{
  id const p = _v[@"model"];
  return RCTBridgingToString(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::chat_template() const
{
  id const p = _v[@"chat_template"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::is_model_asset() const
{
  id const p = _v[@"is_model_asset"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::use_progress_callback() const
{
  id const p = _v[@"use_progress_callback"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_ctx() const
{
  id const p = _v[@"n_ctx"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_batch() const
{
  id const p = _v[@"n_batch"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_ubatch() const
{
  id const p = _v[@"n_ubatch"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_parallel() const
{
  id const p = _v[@"n_parallel"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_threads() const
{
  id const p = _v[@"n_threads"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_gpu_layers() const
{
  id const p = _v[@"n_gpu_layers"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::no_gpu_devices() const
{
  id const p = _v[@"no_gpu_devices"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::flash_attn_type() const
{
  id const p = _v[@"flash_attn_type"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::flash_attn() const
{
  id const p = _v[@"flash_attn"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::cache_type_k() const
{
  id const p = _v[@"cache_type_k"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::cache_type_v() const
{
  id const p = _v[@"cache_type_v"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::use_mlock() const
{
  id const p = _v[@"use_mlock"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::use_mmap() const
{
  id const p = _v[@"use_mmap"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::vocab_only() const
{
  id const p = _v[@"vocab_only"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::NativeContextParams::lora() const
{
  id const p = _v[@"lora"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::lora_scaled() const
{
  id const p = _v[@"lora_scaled"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeContextParamsLora_listElement>> JS::NativeRNLlama::NativeContextParams::lora_list() const
{
  id const p = _v[@"lora_list"];
  return RCTBridgingToOptionalVec(p, ^JS::NativeRNLlama::NativeContextParamsLora_listElement(id itemValue_0) { return JS::NativeRNLlama::NativeContextParamsLora_listElement(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::rope_freq_base() const
{
  id const p = _v[@"rope_freq_base"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::rope_freq_scale() const
{
  id const p = _v[@"rope_freq_scale"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::pooling_type() const
{
  id const p = _v[@"pooling_type"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::ctx_shift() const
{
  id const p = _v[@"ctx_shift"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::kv_unified() const
{
  id const p = _v[@"kv_unified"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::swa_full() const
{
  id const p = _v[@"swa_full"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::n_cpu_moe() const
{
  id const p = _v[@"n_cpu_moe"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeContextParams::embedding() const
{
  id const p = _v[@"embedding"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeContextParams::embd_normalize() const
{
  id const p = _v[@"embd_normalize"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::SpecGetFormattedChatParams::jinja() const
{
  id const p = _v[@"jinja"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::json_schema() const
{
  id const p = _v[@"json_schema"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::tools() const
{
  id const p = _v[@"tools"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::parallel_tool_calls() const
{
  id const p = _v[@"parallel_tool_calls"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::tool_choice() const
{
  id const p = _v[@"tool_choice"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<bool> JS::NativeRNLlama::SpecGetFormattedChatParams::enable_thinking() const
{
  id const p = _v[@"enable_thinking"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::SpecGetFormattedChatParams::add_generation_prompt() const
{
  id const p = _v[@"add_generation_prompt"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::now() const
{
  id const p = _v[@"now"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::SpecGetFormattedChatParams::chat_template_kwargs() const
{
  id const p = _v[@"chat_template_kwargs"];
  return RCTBridgingToOptionalString(p);
}
inline double JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement::type() const
{
  id const p = _v[@"type"];
  return RCTBridgingToDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement::value() const
{
  id const p = _v[@"value"];
  return RCTBridgingToString(p);
}
inline double JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement::token() const
{
  id const p = _v[@"token"];
  return RCTBridgingToDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeCompletionParams::prompt() const
{
  id const p = _v[@"prompt"];
  return RCTBridgingToString(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::n_threads() const
{
  id const p = _v[@"n_threads"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeCompletionParams::jinja() const
{
  id const p = _v[@"jinja"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::NativeCompletionParams::json_schema() const
{
  id const p = _v[@"json_schema"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::NativeCompletionParams::grammar() const
{
  id const p = _v[@"grammar"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeCompletionParams::grammar_lazy() const
{
  id const p = _v[@"grammar_lazy"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeCompletionParams::enable_thinking() const
{
  id const p = _v[@"enable_thinking"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeCompletionParams::thinking_forced_open() const
{
  id const p = _v[@"thinking_forced_open"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement>> JS::NativeRNLlama::NativeCompletionParams::grammar_triggers() const
{
  id const p = _v[@"grammar_triggers"];
  return RCTBridgingToOptionalVec(p, ^JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement(id itemValue_0) { return JS::NativeRNLlama::NativeCompletionParamsGrammar_triggersElement(itemValue_0); });
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeCompletionParams::preserved_tokens() const
{
  id const p = _v[@"preserved_tokens"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::chat_format() const
{
  id const p = _v[@"chat_format"];
  return RCTBridgingToOptionalDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeCompletionParams::reasoning_format() const
{
  id const p = _v[@"reasoning_format"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeCompletionParams::media_paths() const
{
  id const p = _v[@"media_paths"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeCompletionParams::stop() const
{
  id const p = _v[@"stop"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::n_predict() const
{
  id const p = _v[@"n_predict"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::n_probs() const
{
  id const p = _v[@"n_probs"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::top_k() const
{
  id const p = _v[@"top_k"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::top_p() const
{
  id const p = _v[@"top_p"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::min_p() const
{
  id const p = _v[@"min_p"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::xtc_probability() const
{
  id const p = _v[@"xtc_probability"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::xtc_threshold() const
{
  id const p = _v[@"xtc_threshold"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::typical_p() const
{
  id const p = _v[@"typical_p"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::temperature() const
{
  id const p = _v[@"temperature"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::penalty_last_n() const
{
  id const p = _v[@"penalty_last_n"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::penalty_repeat() const
{
  id const p = _v[@"penalty_repeat"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::penalty_freq() const
{
  id const p = _v[@"penalty_freq"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::penalty_present() const
{
  id const p = _v[@"penalty_present"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::mirostat() const
{
  id const p = _v[@"mirostat"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::mirostat_tau() const
{
  id const p = _v[@"mirostat_tau"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::mirostat_eta() const
{
  id const p = _v[@"mirostat_eta"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::dry_multiplier() const
{
  id const p = _v[@"dry_multiplier"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::dry_base() const
{
  id const p = _v[@"dry_base"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::dry_allowed_length() const
{
  id const p = _v[@"dry_allowed_length"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::dry_penalty_last_n() const
{
  id const p = _v[@"dry_penalty_last_n"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeCompletionParams::dry_sequence_breakers() const
{
  id const p = _v[@"dry_sequence_breakers"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::top_n_sigma() const
{
  id const p = _v[@"top_n_sigma"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeCompletionParams::ignore_eos() const
{
  id const p = _v[@"ignore_eos"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<facebook::react::LazyVector<facebook::react::LazyVector<double>>> JS::NativeRNLlama::NativeCompletionParams::logit_bias() const
{
  id const p = _v[@"logit_bias"];
  return RCTBridgingToOptionalVec(p, ^facebook::react::LazyVector<double>(id itemValue_0) { return RCTBridgingToVec(itemValue_0, ^double(id itemValue_1) { return RCTBridgingToDouble(itemValue_1); }); });
}
inline std::optional<double> JS::NativeRNLlama::NativeCompletionParams::seed() const
{
  id const p = _v[@"seed"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<facebook::react::LazyVector<double>> JS::NativeRNLlama::NativeCompletionParams::guide_tokens() const
{
  id const p = _v[@"guide_tokens"];
  return RCTBridgingToOptionalVec(p, ^double(id itemValue_0) { return RCTBridgingToDouble(itemValue_0); });
}
inline bool JS::NativeRNLlama::NativeCompletionParams::emit_partial_completion() const
{
  id const p = _v[@"emit_partial_completion"];
  return RCTBridgingToBool(p);
}
inline bool JS::NativeRNLlama::SpecEnableParallelModeParams::enabled() const
{
  id const p = _v[@"enabled"];
  return RCTBridgingToBool(p);
}
inline std::optional<double> JS::NativeRNLlama::SpecEnableParallelModeParams::n_parallel() const
{
  id const p = _v[@"n_parallel"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::SpecEnableParallelModeParams::n_batch() const
{
  id const p = _v[@"n_batch"];
  return RCTBridgingToOptionalDouble(p);
}
inline double JS::NativeRNLlama::NativeParallelCompletionParamsGrammar_triggersElement::type() const
{
  id const p = _v[@"type"];
  return RCTBridgingToDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeParallelCompletionParamsGrammar_triggersElement::value() const
{
  id const p = _v[@"value"];
  return RCTBridgingToString(p);
}
inline double JS::NativeRNLlama::NativeParallelCompletionParamsGrammar_triggersElement::token() const
{
  id const p = _v[@"token"];
  return RCTBridgingToDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeParallelCompletionParams::prompt() const
{
  id const p = _v[@"prompt"];
  return RCTBridgingToString(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::n_threads() const
{
  id const p = _v[@"n_threads"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeParallelCompletionParams::jinja() const
{
  id const p = _v[@"jinja"];
  return RCTBridgingToOptionalBool(p);
}
inline NSString *JS::NativeRNLlama::NativeParallelCompletionParams::json_schema() const
{
  id const p = _v[@"json_schema"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::NativeParallelCompletionParams::grammar() const
{
  id const p = _v[@"grammar"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeParallelCompletionParams::grammar_lazy() const
{
  id const p = _v[@"grammar_lazy"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeParallelCompletionParams::enable_thinking() const
{
  id const p = _v[@"enable_thinking"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeParallelCompletionParams::thinking_forced_open() const
{
  id const p = _v[@"thinking_forced_open"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<facebook::react::LazyVector<JS::NativeRNLlama::NativeParallelCompletionParamsGrammar_triggersElement>> JS::NativeRNLlama::NativeParallelCompletionParams::grammar_triggers() const
{
  id const p = _v[@"grammar_triggers"];
  return RCTBridgingToOptionalVec(p, ^JS::NativeRNLlama::NativeParallelCompletionParamsGrammar_triggersElement(id itemValue_0) { return JS::NativeRNLlama::NativeParallelCompletionParamsGrammar_triggersElement(itemValue_0); });
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeParallelCompletionParams::preserved_tokens() const
{
  id const p = _v[@"preserved_tokens"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::chat_format() const
{
  id const p = _v[@"chat_format"];
  return RCTBridgingToOptionalDouble(p);
}
inline NSString *JS::NativeRNLlama::NativeParallelCompletionParams::reasoning_format() const
{
  id const p = _v[@"reasoning_format"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeParallelCompletionParams::media_paths() const
{
  id const p = _v[@"media_paths"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeParallelCompletionParams::stop() const
{
  id const p = _v[@"stop"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::n_predict() const
{
  id const p = _v[@"n_predict"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::n_probs() const
{
  id const p = _v[@"n_probs"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::top_k() const
{
  id const p = _v[@"top_k"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::top_p() const
{
  id const p = _v[@"top_p"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::min_p() const
{
  id const p = _v[@"min_p"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::xtc_probability() const
{
  id const p = _v[@"xtc_probability"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::xtc_threshold() const
{
  id const p = _v[@"xtc_threshold"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::typical_p() const
{
  id const p = _v[@"typical_p"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::temperature() const
{
  id const p = _v[@"temperature"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::penalty_last_n() const
{
  id const p = _v[@"penalty_last_n"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::penalty_repeat() const
{
  id const p = _v[@"penalty_repeat"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::penalty_freq() const
{
  id const p = _v[@"penalty_freq"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::penalty_present() const
{
  id const p = _v[@"penalty_present"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::mirostat() const
{
  id const p = _v[@"mirostat"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::mirostat_tau() const
{
  id const p = _v[@"mirostat_tau"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::mirostat_eta() const
{
  id const p = _v[@"mirostat_eta"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::dry_multiplier() const
{
  id const p = _v[@"dry_multiplier"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::dry_base() const
{
  id const p = _v[@"dry_base"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::dry_allowed_length() const
{
  id const p = _v[@"dry_allowed_length"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::dry_penalty_last_n() const
{
  id const p = _v[@"dry_penalty_last_n"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<facebook::react::LazyVector<NSString *>> JS::NativeRNLlama::NativeParallelCompletionParams::dry_sequence_breakers() const
{
  id const p = _v[@"dry_sequence_breakers"];
  return RCTBridgingToOptionalVec(p, ^NSString *(id itemValue_0) { return RCTBridgingToString(itemValue_0); });
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::top_n_sigma() const
{
  id const p = _v[@"top_n_sigma"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<bool> JS::NativeRNLlama::NativeParallelCompletionParams::ignore_eos() const
{
  id const p = _v[@"ignore_eos"];
  return RCTBridgingToOptionalBool(p);
}
inline std::optional<facebook::react::LazyVector<facebook::react::LazyVector<double>>> JS::NativeRNLlama::NativeParallelCompletionParams::logit_bias() const
{
  id const p = _v[@"logit_bias"];
  return RCTBridgingToOptionalVec(p, ^facebook::react::LazyVector<double>(id itemValue_0) { return RCTBridgingToVec(itemValue_0, ^double(id itemValue_1) { return RCTBridgingToDouble(itemValue_1); }); });
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::seed() const
{
  id const p = _v[@"seed"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<facebook::react::LazyVector<double>> JS::NativeRNLlama::NativeParallelCompletionParams::guide_tokens() const
{
  id const p = _v[@"guide_tokens"];
  return RCTBridgingToOptionalVec(p, ^double(id itemValue_0) { return RCTBridgingToDouble(itemValue_0); });
}
inline bool JS::NativeRNLlama::NativeParallelCompletionParams::emit_partial_completion() const
{
  id const p = _v[@"emit_partial_completion"];
  return RCTBridgingToBool(p);
}
inline NSString *JS::NativeRNLlama::NativeParallelCompletionParams::load_state_path() const
{
  id const p = _v[@"load_state_path"];
  return RCTBridgingToOptionalString(p);
}
inline NSString *JS::NativeRNLlama::NativeParallelCompletionParams::save_state_path() const
{
  id const p = _v[@"save_state_path"];
  return RCTBridgingToOptionalString(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeParallelCompletionParams::save_state_size() const
{
  id const p = _v[@"save_state_size"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeEmbeddingParams::embd_normalize() const
{
  id const p = _v[@"embd_normalize"];
  return RCTBridgingToOptionalDouble(p);
}
inline std::optional<double> JS::NativeRNLlama::NativeRerankParams::normalize() const
{
  id const p = _v[@"normalize"];
  return RCTBridgingToOptionalDouble(p);
}
inline NSString *JS::NativeRNLlama::SpecInitMultimodalParams::path() const
{
  id const p = _v[@"path"];
  return RCTBridgingToString(p);
}
inline bool JS::NativeRNLlama::SpecInitMultimodalParams::use_gpu() const
{
  id const p = _v[@"use_gpu"];
  return RCTBridgingToBool(p);
}
inline NSString *JS::NativeRNLlama::SpecInitVocoderParams::path() const
{
  id const p = _v[@"path"];
  return RCTBridgingToString(p);
}
inline std::optional<double> JS::NativeRNLlama::SpecInitVocoderParams::n_batch() const
{
  id const p = _v[@"n_batch"];
  return RCTBridgingToOptionalDouble(p);
}
NS_ASSUME_NONNULL_END
#endif // RNLlamaSpec_H
